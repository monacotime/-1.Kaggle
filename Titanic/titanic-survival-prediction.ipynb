{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": false,
    "_kg_hide-output": false,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "#!pip install scikit-learn==0.21.2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "pd.set_option('max_columns', None, \"max_rows\", None)\n",
    "from numpy.random import seed\n",
    "seed(1002)\n",
    "tf.random.set_seed(1002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "#Declare Global variables \n",
    "train_path = \"../input/titanic/train.csv\"\n",
    "test_path = \"../input/titanic/test.csv\"\n",
    "mapping = {'Col': 'Other',\n",
    "           'Major': 'Other',\n",
    "           'Ms': 'Miss',\n",
    "           'Mlle': 'Miss',\n",
    "           'Sir': 'Royal',\n",
    "           'Jonkheer': 'Royal',\n",
    "           'Countess': 'Royal',\n",
    "           'Lady': 'Royal',\n",
    "           'Capt': 'Other',\n",
    "           'Dona': 'Royal',\n",
    "           'Mme': 'Mrs',\n",
    "           'Don': 'Royal',\n",
    "           'Dr': 'Other',\n",
    "           'Rev' : 'Other'}\n",
    "continuous = ['Age', 'Fare', 'Parch', 'SibSp', 'Family_Size', \"Family_Survival\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(train_path,test_path):\n",
    "    train = pd.read_csv(train_path)\n",
    "    test = pd.read_csv(test_path)\n",
    "    df = pd.concat([train, test], axis = 0, sort = False)\n",
    "    df[\"Title\"] = df[\"Name\"].str.extract(r\"([a-zA-Z]+)\\.\", expand = True)\n",
    "    df.replace({\"Title\": mapping}, inplace = True)\n",
    "    title_ages = dict(df.groupby('Title')['Age'].median())\n",
    "    df[\"age_med\"] = df[\"Title\"].apply(lambda a : title_ages[a])\n",
    "    df[\"Age\"].fillna(df[\"age_med\"], inplace = True)\n",
    "    #df[\"Pclass_rel\"] = df[\"Pclass\"]\n",
    "    submit = df[pd.isnull(df[\"Survived\"])][[\"PassengerId\",\"Survived\"]]\n",
    "    df[\"Fare\"].fillna(df[\"Fare\"][df[\"Pclass\"] == 3].median(), inplace = True)\n",
    "    df['Family_Size'] = df['Parch'] + df['SibSp'] + 1\n",
    "    df.loc[:,'FsizeD'] = 'Alone'\n",
    "    df.loc[(df['Family_Size'] > 1),'FsizeD'] = 'Small'\n",
    "    df.loc[(df['Family_Size'] > 4),'FsizeD'] = 'Big'\n",
    "    # Family Survival (https://www.kaggle.com/konstantinmasich/titanic-0-82-0-83)\n",
    "    df['Last_Name'] = df['Name'].apply(lambda x: str.split(x, \",\")[0])\n",
    "    DEFAULT_SURVIVAL_VALUE = 0.5\n",
    "    df['Family_Survival'] = DEFAULT_SURVIVAL_VALUE\n",
    "    for grp, grp_df in df[['Survived','Name', 'Last_Name', 'Fare', 'Ticket', 'PassengerId', \n",
    "                           'SibSp', 'Parch', 'Age', 'Cabin']].groupby(['Last_Name', 'Fare']):\n",
    "        if (len(grp_df) != 1):\n",
    "            # A Family group is found.\n",
    "            for ind, row in grp_df.iterrows():\n",
    "                smax = grp_df.drop(ind)['Survived'].max()\n",
    "                smin = grp_df.drop(ind)['Survived'].min()\n",
    "                passID = row['PassengerId']\n",
    "                if (smax == 1.0):\n",
    "                    df.loc[df['PassengerId'] == passID, 'Family_Survival'] = 1\n",
    "                elif (smin == 0.0):\n",
    "                    df.loc[df['PassengerId'] == passID, 'Family_Survival'] = 0\n",
    "    for _, grp_df in df.groupby('Ticket'):\n",
    "        if (len(grp_df) != 1):\n",
    "            for ind, row in grp_df.iterrows():\n",
    "                if (row['Family_Survival'] == 0) | (row['Family_Survival']== 0.5):\n",
    "                    smax = grp_df.drop(ind)['Survived'].max()\n",
    "                    smin = grp_df.drop(ind)['Survived'].min()\n",
    "                    passID = row['PassengerId']\n",
    "                    if (smax == 1.0):\n",
    "                        df.loc[df['PassengerId'] == passID, 'Family_Survival'] = 1\n",
    "                    elif (smin == 0.0):\n",
    "                        df.loc[df['PassengerId'] == passID, 'Family_Survival'] = 0\n",
    "    df['Embarked'].fillna(method='backfill', inplace=True)\n",
    "    df['Sex'] = df['Sex'].astype('category').cat.codes\n",
    "    df.drop(['Cabin', 'Name', 'Ticket', 'PassengerId', 'age_med', 'Last_Name'], axis=1, inplace=True)\n",
    "    df = pd.get_dummies(df, columns = [\"Embarked\", \"Pclass\", \"Title\", \"FsizeD\"])\n",
    "    scaler = StandardScaler()\n",
    "    for var in continuous:\n",
    "        df[var] = scaler.fit_transform(df[var].astype('float64').values.reshape(-1, 1))\n",
    "    x_train = df[pd.notnull(df[\"Survived\"])].drop(\"Survived\",axis = 1)\n",
    "    y_train = df[pd.notnull(df[\"Survived\"])][\"Survived\"].astype(int)\n",
    "    x_test = df[pd.isnull(df[\"Survived\"])].drop(\"Survived\",axis = 1)\n",
    "    return x_train, y_train, x_test, submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, submit = prepare_data(train_path, test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [[8],[16],[8,4],[16,8],[24,16,8],[24,8]]\n",
    "activation = [\"relu\",\"linear\",\"tanh\"]\n",
    "optimizer = [\"SGD\",\"RMSprop\",\"Adam\"]\n",
    "dropout = [0.0,0.2]\n",
    "batch_size = [32,64,128]\n",
    "epochs = [50,75]\n",
    "param_grid = dict(batch_size = batch_size, \n",
    "                  epochs = epochs,\n",
    "                  lyr = layers,\n",
    "                  act = activation,\n",
    "                  opt = optimizer, \n",
    "                  dr = dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(lyr = [13,8], act = \"relu\", opt = \"adam\", dr = 0.2):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(lyr[0], input_dim = 22, activation = act))\n",
    "    model.add(Dropout(dr))\n",
    "    for i in lyr[1:]:\n",
    "        model.add(Dense(i, activation = act))\n",
    "    model.add(Dense(1, activation = \"sigmoid\"))\n",
    "    model.compile(loss = \"binary_crossentropy\", optimizer = opt, metrics = [\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search():\n",
    "  model = KerasClassifier(build_fn = create_model, verbose = 1)\n",
    "  grid = GridSearchCV(estimator = model, param_grid = param_grid, n_jobs = -1, cv = 2, verbose=2)\n",
    "  grid_result = grid.fit(x_train, y_train)\n",
    "  return grid_result"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "**Now that we have done all this,**\n",
    "<br>\n",
    "<br>all we have to now do is just:\n",
    "<br>call the search method and store the result.\n",
    "<br>use the result to see the best parameter\n",
    "<br>\n",
    "<br>**BUT**\n",
    "<br>\n",
    "<br>The current kernal in kaggle uses the scikit-learn version 0.23.0\n",
    "<br>This version of Scikit-learn has got a bug in the GridSearchCV\n",
    "<br>and the only way to fix this is to roll back on a more stable release where \n",
    "<br>GridSearchCV is working ( I choose v0.21.2)\n",
    "<br>\n",
    "<br>**BUT**\n",
    "<br>\n",
    "<br>To roll to this version, i need to use conda inside of kaggle and that thing is also bugged out rn\n",
    "<br>\n",
    "<br>So it has become a rabbit hole of tryint to fix GridSearchCV -> Scikit-learn -> Conda installs\n",
    "<br>where I have already spent so many hours into\n",
    "<br>\n",
    "<br>**THEREFORE**\n",
    "<br>\n",
    "<br>I ran the GridSearchCV locally and stored its results in a dataframe\n",
    "<br>\n",
    "<br>Below are the output of codes that I ran locally:\n",
    "<br>\n",
    "> ```#codes to be run if GridSearchCV() is running properly\n",
    "> search_result = search()\n",
    "> view = pd.DataFrame(search_result.cv_results_)\n",
    "> view.to_csv('gridsearch_cv_results.csv', index=False)\n",
    "> search_result.best_params_```\n",
    "> \n",
    "---\n",
    "> search_result = search()\n",
    "<br>\n",
    "```Fitting 2 folds for each of 648 candidates, totalling 1296 fits\n",
    "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
    "[Parallel(n_jobs=-1)]: Done  37 tasks        | elapsed:   41.0s\n",
    "[Parallel(n_jobs=-1)]: Done 158 tasks        | elapsed:  3.0min\n",
    "[Parallel(n_jobs=-1)]: Done 361 tasks        | elapsed:  5.8min\n",
    "[Parallel(n_jobs=-1)]: Done 644 tasks        | elapsed: 10.5min\n",
    "[Parallel(n_jobs=-1)]: Done 1009 tasks       | elapsed: 16.3min\n",
    "[Parallel(n_jobs=-1)]: Done 1296 out of 1296 | elapsed: 20.1min finished```\n",
    "\n",
    "> search_result\n",
    "<br>\n",
    "```GridSearchCV(cv=2, error_score='raise-deprecating',\n",
    "             estimator=<keras.wrappers.scikit_learn.KerasClassifier object at 0x7f79f41f2550>,\n",
    "             iid='warn', n_jobs=-1,\n",
    "             param_grid={'act': ['relu', 'linear', 'tanh'],\n",
    "                         'batch_size': [32, 64, 128], 'dr': [0.0, 0.2],\n",
    "                         'epochs': [50, 75],\n",
    "                         'lyr': [[8], [16], [8, 4], [16, 8], [24, 16, 8],\n",
    "                                 [24, 8]],\n",
    "                         'opt': ['SGD', 'RMSprop', 'Adam']},\n",
    "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
    "             scoring=None, verbose=2)```\n",
    "\n",
    "> search_result.best_params_\n",
    "<br>\n",
    "```{'act': 'tanh',\n",
    " 'batch_size': 32,\n",
    " 'dr': 0.0,\n",
    " 'epochs': 75,\n",
    " 'lyr': [16, 8],\n",
    " 'opt': 'RMSprop'}```\n",
    "\n",
    "---\n",
    "\n",
    "**Some different samples of batch size and their co-responding acc**\n",
    "<br>batch 32 : 85.07%\n",
    "<br>batch 16 : 85.41%\n",
    "<br>batch 1 : 85.63%\n",
    "<br>other \n",
    "<br>#Results: 84.06% (1.45%) <13,8,1>\n",
    "<br>#Results: 84.29% (1.87%) <13,8,1> with dr 0.2\n",
    "<br>#Results: 84.40% (1.72%) <13,8,1> with dr 0.2 epochs = 100 (choosen)\n",
    "<br>#Results: 84.17% (0.90%) <9,9,5> with dr 0.2 epochs = 100\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_split.py:297: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: 82.94% (2.32%)\n"
     ]
    }
   ],
   "source": [
    "estimator = KerasClassifier(build_fn = create_model, epochs = 100, batch_size = 10, verbose = 0)\n",
    "kfold = StratifiedKFold(n_splits = 5, random_state = 42, shuffle = False)\n",
    "results = cross_val_score(estimator, x_train, y_train, cv = kfold)\n",
    "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc66c25dc90>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.fit(x_train, y_train, epochs = 100, batch_size = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "The Ultimate oneliner\n",
    "\n",
    "---\n",
    "```submit[\"Survived\"] = [int(np.round(best_nn.predict(x_test.loc[x].to_numpy().reshape(1,18)),0)) for x in range(0,submit[\"Survived\"].size)]```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived\n",
       "0          892         0\n",
       "1          893         0\n",
       "2          894         0\n",
       "3          895         0\n",
       "4          896         1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit[\"Survived\"] = estimator.predict(x_test)\n",
    "submit[\"Survived\"] = [int(np.round(x,0)) for x in submit[\"Survived\"]]\n",
    "submit.to_csv('predictions.csv', index=False)\n",
    "submit.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
